"""
BLOG GENERATION WORKFLOW USING LANGGraph
=========================================
This example demonstrates a two-step blog generation system:
1. Generate outline from title
2. Generate full blog content from outline

Workflow Visualization:
    START â†’ [Outline Generator] â†’ [Content Generator] â†’ END
        â†“            â†“                     â†“              â†“
      Title      Outline Created      Blog Written    Final Output
"""

# ============================================
# SECTION 1: IMPORT STATEMENTS
# ============================================

# Core LangGraph components for creating workflow graphs
from langgraph.graph import StateGraph, START, END

# TypedDict for defining strict state structure
from typing import TypedDict

# AzureChatOpenAI for accessing GPT models via Azure
from langchain_openai import AzureChatOpenAI

# dotenv for loading environment variables securely
from dotenv import load_dotenv

# os for accessing environment variables
import os

# ============================================
# SECTION 2: LOAD ENVIRONMENT VARIABLES
# ============================================

# Load API keys and configuration from .env file
# This keeps sensitive information out of the code
load_dotenv()

# ============================================
# SECTION 3: INITIALIZE THE LANGUAGE MODEL
# ============================================

"""
LLM Configuration:
- deployment_name: Which Azure deployment to use
- model_name: Specific GPT model (gpt-4.1-mini)
- temperature: 0.1 = low creativity, focused responses
- max_tokens: 500 = limit response length
- azure_endpoint: Azure service URL (from environment variable)
- api_version: Azure API version (from environment variable)
- api_key: Authentication key (from environment variable)
- azure_deployment: Which deployed model to use
"""
llm = AzureChatOpenAI(
    deployment_name="gpt-4.1-mini",
    model_name="gpt-4.1-mini",
    temperature=0.1,
    max_tokens=500,
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_version=os.getenv("AZURE_OPENAI_VERSION"),
    api_key=os.getenv("OPENAI_API_KEY"),
    azure_deployment="gpt-4.1-mini"
)

# ============================================
# SECTION 4: DEFINE STATE STRUCTURE
# ============================================

"""
BlogState: The data structure that flows through our workflow.

This TypedDict defines exactly what data our workflow handles:
- title: User-provided blog title (string)
- outline: Generated blog structure (string)
- content: Final blog post (string)

Think of this as a "data container" that gets passed between nodes.
Each node can read from and write to different parts of this container.
"""
class BlogState(TypedDict):
    """State structure for blog generation workflow"""
    title: str      # Input: Blog title provided by user
    outline: str    # Intermediate: Outline generated by first LLM call
    content: str    # Output: Final blog content generated by second LLM call

# ============================================
# SECTION 5: NODE 1 - OUTLINE GENERATOR
# ============================================

"""
Node Function: generate_outline

Purpose: Takes a blog title and generates a detailed outline

Input: State containing 'title'
Process: Calls LLM with prompt to create outline
Output: Updates state with 'outline'

This is the first step in our content creation pipeline.
"""
def generate_outline(state: BlogState) -> BlogState:
    """
    Generate a blog outline based on the provided title.
    
    Workflow:
    1. Extract title from incoming state
    2. Create prompt asking LLM to create outline
    3. Send prompt to LLM
    4. Get outline response
    5. Update state with outline
    6. Return updated state
    
    Parameters:
        state: Dictionary with 'title' key
        
    Returns:
        Updated state with 'outline' key populated
    """
    
    # STEP 1: Extract the title from the state
    # The state arrives with the user's blog title
    title = state['title']
    print(f"[Node 1] Generating outline for: {title}")
    
    # STEP 2: Create prompt for outline generation
    # This tells the LLM what we want (an outline for this topic)
    prompt = f"Create a detailed outline for a blog about: {title}"
    print(f"[Node 1] Sending to LLM: {prompt[:50]}...")
    
    # STEP 3: Call LLM and get response
    # .invoke() sends prompt to Azure OpenAI
    # .content extracts the text response
    outline_response = llm.invoke(prompt)
    outline = outline_response.content
    print(f"[Node 1] Outline generated ({len(outline)} chars)")
    
    # STEP 4: Update state with the outline
    # Add/update the 'outline' key in our state dictionary
    state['outline'] = outline
    
    # STEP 5: Return updated state
    # LangGraph will pass this to the next node (content generator)
    return state

# ============================================
# SECTION 6: NODE 2 - CONTENT GENERATOR
# ============================================

"""
Node Function: generate_content

Purpose: Takes title and outline to generate full blog content

Input: State containing 'title' and 'outline'
Process: Calls LLM with both title and outline as context
Output: Updates state with 'content'

This is the second step in our content creation pipeline.
"""
def generate_content(state: BlogState) -> BlogState:
    """
    Generate full blog content based on title and outline.
    
    Workflow:
    1. Extract title and outline from state
    2. Create prompt asking LLM to write blog using outline
    3. Send prompt to LLM
    4. Get blog content response
    5. Update state with content
    6. Return updated state
    
    Parameters:
        state: Dictionary with 'title' and 'outline' keys
        
    Returns:
        Updated state with 'content' key populated
    """
    
    # STEP 1: Extract data from state
    # We now have both the original title and the generated outline
    title = state['title']
    outline = state['outline']
    print(f"[Node 2] Generating content for: {title}")
    print(f"[Node 2] Using outline: {outline[:50]}...")
    
    # STEP 2: Create prompt for content generation
    # We provide both title and outline as context to the LLM
    prompt = f"""Write a detailed blog post with this title: {title}

Use this outline as your structure:
{outline}

Write a comprehensive, well-structured blog post."""
    print(f"[Node 2] Sending to LLM: {prompt[:50]}...")
    
    # STEP 3: Call LLM and get response
    # This LLM call uses the outline from the first call
    content_response = llm.invoke(prompt)
    content = content_response.content
    print(f"[Node 2] Content generated ({len(content)} chars)")
    
    # STEP 4: Update state with the content
    # Add/update the 'content' key in our state dictionary
    state['content'] = content
    
    # STEP 5: Return updated state
    # LangGraph will pass this to the END node
    return state

# ============================================
# SECTION 7: BUILD THE GRAPH
# ============================================

"""
Graph Construction Steps:
1. Create StateGraph object with our BlogState type
2. Add nodes (outline_generator and content_generator)
3. Add edges to connect nodes in sequence
4. Compile graph into executable workflow

Visual Workflow:
    [START] â†’ [outline_generator] â†’ [content_generator] â†’ [END]
        â†“             â†“                     â†“              â†“
    Input       Generate Outline     Write Full Blog    Output
    (Title)                          (Using Outline)   (Content)
"""

# Create a new StateGraph for our BlogState structure
graph = StateGraph(BlogState)

# Add first node: Outline generator
# This node takes title and creates outline
graph.add_node('outline_generator', generate_outline)

# Add second node: Content generator
# This node takes title + outline and creates full blog
graph.add_node('content_generator', generate_content)

# ============================================
# SECTION 8: CONNECT NODES WITH EDGES
# ============================================

"""
Edge Definition:
- START â†’ outline_generator: Begin with outline generation
- outline_generator â†’ content_generator: After outline, generate content
- content_generator â†’ END: After content, workflow is complete

This creates a linear, sequential workflow.
"""
graph.add_edge(START, 'outline_generator')
graph.add_edge('outline_generator', 'content_generator')
graph.add_edge('content_generator', END)

# ============================================
# SECTION 9: COMPILE THE GRAPH
# ============================================

"""
.compile() transforms our graph definition into an executable workflow.

Before: Graph is a blueprint (nodes and edges defined)
After: Graph is a runnable system with .invoke() method

This is like compiling source code into an executable program.
"""
workflow = graph.compile()
print("[INFO] Blog generation workflow compiled successfully!")

# ============================================
# SECTION 10: EXECUTE WORKFLOW
# ============================================

# Define initial state with a blog title
# This is our starting point - only the title is provided
initial_state = {'title': 'The Future of Artificial Intelligence'}

print("\n" + "="*60)
print("STARTING BLOG GENERATION WORKFLOW")
print("="*60)
print(f"Input title: {initial_state['title']}")

"""
.invoke() Execution Process:
1. Takes initial_state with 'title'
2. START passes it to outline_generator node
3. outline_generator: Calls LLM, creates outline, updates state
4. outline_generator passes updated state to content_generator
5. content_generator: Calls LLM, creates content, updates state
6. content_generator passes final state to END
7. Returns complete state with title, outline, and content
"""
final_state = workflow.invoke(initial_state)

# ============================================
# SECTION 11: DISPLAY RESULTS
# ============================================

print("\n" + "="*60)
print("BLOG GENERATION COMPLETE!")
print("="*60)

print(f"\nðŸ“ TITLE: {final_state['title']}")
print(f"\nðŸ“‹ OUTLINE ({len(final_state['outline'])} characters):")
print("-" * 40)
print(final_state['outline'])
print("-" * 40)

print(f"\nðŸ“„ CONTENT ({len(final_state['content'])} characters):")
print("-" * 40)
print(final_state['content'])
print("-" * 40)

# ============================================
# SECTION 12: TEST WITH MULTIPLE TITLES
# ============================================

print("\n" + "="*60)
print("TESTING WITH DIFFERENT TITLES")
print("="*60)

test_titles = [
    "How to Learn Programming in 2024",
    "The Impact of Climate Change on Agriculture",
    "10 Benefits of Regular Exercise"
]

for i, title in enumerate(test_titles, 1):
    print(f"\nTest #{i}: {title}")
    
    # Run workflow for each title
    state = workflow.invoke({'title': title})
    
    # Show summary
    outline_preview = state['outline'][:100] + "..." if len(state['outline']) > 100 else state['outline']
    content_preview = state['content'][:100] + "..." if len(state['content']) > 100 else state['content']
    
    print(f"Outline preview: {outline_preview}")
    print(f"Content preview: {content_preview}")
    print("-" * 40)

print("="*60)
print("All tests completed! ðŸŽ‰")

# ============================================
# SECTION 13: KEY CONCEPTS DEMONSTRATED
# ============================================
"""
1. CHAINING: Multiple LLM calls in sequence (output of one = input to next)
2. STATE EVOLUTION: State grows as it moves through workflow
   - Start: {'title': '...'}
   - After Node 1: {'title': '...', 'outline': '...'}
   - After Node 2: {'title': '...', 'outline': '...', 'content': '...'}
3. WORKFLOW DESIGN: Breaking complex tasks into manageable steps
4. REUSABILITY: Same LLM used for different purposes with different prompts
5. DEBUGGING: Print statements show workflow progress

This pattern can be extended for more complex content creation:
  Title â†’ Outline â†’ Research â†’ Draft â†’ Edit â†’ Final
"""